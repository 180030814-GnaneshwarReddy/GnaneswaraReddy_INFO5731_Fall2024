{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/180030814-GnaneshwarReddy/GnaneswaraReddy_INFO5731_Fall2024/blob/main/Palem_Gnaneswara_Exercise_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 3**\n",
        "\n",
        "The purpose of this exercise is to explore various aspects of text analysis, including feature extraction, feature selection, and text similarity ranking.\n",
        "\n",
        "**Expectations**:\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of Friday, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n",
        "\n",
        "**Please check that the link you submitted can be opened and points to the correct assignment.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting **text classification or text mining task** and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features. **Your dataset must be text.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAZj4PHB70nf"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "Task: Sentiment Analysis\n",
        "Useful features to buld machne learnng model:\n",
        "1. Bag of Words: it is a representation of text data, where each word in the text is represented as a feature.\n",
        "2. N-grams: N-grams are sequences of n-consecutive words.\n",
        "3. Parts of speech Tags: This method assigns each word in the text to a part of speech tag, such as noun, verb, adjective, etc.\n",
        "4. Sentiment Lexicon sores: These are predefined dictionaries that associate with sentiment scores.\n",
        "5. Text readability and length features: These features are used to signal the extremity of the expressed sentiment.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoQX5s4O70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e800e9e-71c4-429e-a2c3-b507407a9c24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "!pip install nltk scikit-learn textblob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing required libraries\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from textblob import TextBlob\n",
        "from nltk import pos_tag, word_tokenize\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from textblob import TextBlob\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.util import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "Lmm3i8gQpI-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading NTLK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('sentiwordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGpS26fEpMOe",
        "outputId": "3e6ae1d7-51bd-4f0f-da7b-62de21bb5be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sample input text\n",
        "texts = [\n",
        "    \"I absolutely love this product! It works like a charm and exceeded my expectations.\",\n",
        "    \"This is the worst experience I've ever had. Terrible service and awful product.\",\n",
        "    \"The product is okay. Nothing special but does the job.\",\n",
        "    \"I'm not sure if I like this. It's not what I expected but it's not terrible either.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "9XC3TSJDpPOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Bag of Words\n",
        "vectorizer = CountVectorizer()\n",
        "bow_matrix = vectorizer.fit_transform(texts)\n",
        "print(\"Bag of Words Features:\\n\", bow_matrix.toarray())\n",
        "print(\"BoW Vocabulary:\\n\", vectorizer.get_feature_names_out())\n",
        "\n",
        "#2. N-grams\n",
        "bigram_vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
        "bigram_matrix = bigram_vectorizer.fit_transform(texts)\n",
        "print(\"\\nBigrams Features:\\n\", bigram_matrix.toarray())\n",
        "print(\"Bigram Vocabulary:\\n\", bigram_vectorizer.get_feature_names_out())\n",
        "\n",
        "#3. POS Tagging\n",
        "pos_tags = [pos_tag(word_tokenize(text)) for text in texts]\n",
        "print(\"\\nPart of Speech Tags:\\n\", pos_tags)\n",
        "\n",
        "#4. Sentiment Lexicon Scores using TextBlob\n",
        "for text in texts:\n",
        "    blob = TextBlob(text)\n",
        "    sentiment = blob.sentiment.polarity  # Sentiment polarity score from -1 (negative) to +1 (positive)\n",
        "    print(f\"\\nText: '{text}'\")\n",
        "    print(f\"Sentiment Score: {sentiment}\")\n",
        "\n",
        "#5. Text Readability and Length-Based Features\n",
        "for text in texts:\n",
        "    num_sentences = len(sent_tokenize(text))\n",
        "    num_words = len(word_tokenize(text))\n",
        "    avg_word_length = sum(len(word) for word in word_tokenize(text)) / num_words\n",
        "    print(f\"\\nText: '{text}'\")\n",
        "    print(f\"Number of Sentences: {num_sentences}\")\n",
        "    print(f\"Number of Words: {num_words}\")\n",
        "    print(f\"Average Word Length: {avg_word_length:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgd7RgD5pXml",
        "outputId": "57ae6a52-40a1-4862-e888-1cf9d0b6ac62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words Features:\n",
            " [[1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0]\n",
            " [0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1]\n",
            " [0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 2 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 2 0 1 0 0 3 0 0 0 0 0 1 1 0 1 0 1 0 0]]\n",
            "BoW Vocabulary:\n",
            " ['absolutely' 'and' 'awful' 'but' 'charm' 'does' 'either' 'ever'\n",
            " 'exceeded' 'expectations' 'expected' 'experience' 'had' 'if' 'is' 'it'\n",
            " 'job' 'like' 'love' 'my' 'not' 'nothing' 'okay' 'product' 'service'\n",
            " 'special' 'sure' 'terrible' 'the' 'this' 've' 'what' 'works' 'worst']\n",
            "\n",
            "Bigrams Features:\n",
            " [[1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            "  0 0 0 1 0 0 1 0]\n",
            " [0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
            "  1 1 0 0 1 0 0 1]\n",
            " [0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 1\n",
            "  0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 2 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0\n",
            "  0 0 1 0 0 1 0 0]]\n",
            "Bigram Vocabulary:\n",
            " ['absolutely love' 'and awful' 'and exceeded' 'awful product' 'but does'\n",
            " 'but it' 'charm and' 'does the' 'ever had' 'exceeded my' 'expected but'\n",
            " 'experience ve' 'had terrible' 'if like' 'is okay' 'is the' 'it not'\n",
            " 'it works' 'like charm' 'like this' 'love this' 'my expectations'\n",
            " 'not sure' 'not terrible' 'not what' 'nothing special' 'okay nothing'\n",
            " 'product is' 'product it' 'service and' 'special but' 'sure if'\n",
            " 'terrible either' 'terrible service' 'the job' 'the product' 'the worst'\n",
            " 'this is' 'this it' 'this product' 've ever' 'what expected' 'works like'\n",
            " 'worst experience']\n",
            "\n",
            "Part of Speech Tags:\n",
            " [[('I', 'PRP'), ('absolutely', 'RB'), ('love', 'VBP'), ('this', 'DT'), ('product', 'NN'), ('!', '.'), ('It', 'PRP'), ('works', 'VBZ'), ('like', 'IN'), ('a', 'DT'), ('charm', 'NN'), ('and', 'CC'), ('exceeded', 'VBD'), ('my', 'PRP$'), ('expectations', 'NNS'), ('.', '.')], [('This', 'DT'), ('is', 'VBZ'), ('the', 'DT'), ('worst', 'JJS'), ('experience', 'NN'), ('I', 'PRP'), (\"'ve\", 'VBP'), ('ever', 'RB'), ('had', 'VBN'), ('.', '.'), ('Terrible', 'JJ'), ('service', 'NN'), ('and', 'CC'), ('awful', 'JJ'), ('product', 'NN'), ('.', '.')], [('The', 'DT'), ('product', 'NN'), ('is', 'VBZ'), ('okay', 'JJ'), ('.', '.'), ('Nothing', 'VBG'), ('special', 'JJ'), ('but', 'CC'), ('does', 'VBZ'), ('the', 'DT'), ('job', 'NN'), ('.', '.')], [('I', 'PRP'), (\"'m\", 'VBP'), ('not', 'RB'), ('sure', 'JJ'), ('if', 'IN'), ('I', 'PRP'), ('like', 'VBP'), ('this', 'DT'), ('.', '.'), ('It', 'PRP'), (\"'s\", 'VBZ'), ('not', 'RB'), ('what', 'WP'), ('I', 'PRP'), ('expected', 'VBD'), ('but', 'CC'), ('it', 'PRP'), (\"'s\", 'VBZ'), ('not', 'RB'), ('terrible', 'JJ'), ('either', 'RB'), ('.', '.')]]\n",
            "\n",
            "Text: 'I absolutely love this product! It works like a charm and exceeded my expectations.'\n",
            "Sentiment Score: 0.625\n",
            "\n",
            "Text: 'This is the worst experience I've ever had. Terrible service and awful product.'\n",
            "Sentiment Score: -1.0\n",
            "\n",
            "Text: 'The product is okay. Nothing special but does the job.'\n",
            "Sentiment Score: 0.4285714285714286\n",
            "\n",
            "Text: 'I'm not sure if I like this. It's not what I expected but it's not terrible either.'\n",
            "Sentiment Score: 0.05000000000000001\n",
            "\n",
            "Text: 'I absolutely love this product! It works like a charm and exceeded my expectations.'\n",
            "Number of Sentences: 2\n",
            "Number of Words: 16\n",
            "Average Word Length: 4.38\n",
            "\n",
            "Text: 'This is the worst experience I've ever had. Terrible service and awful product.'\n",
            "Number of Sentences: 2\n",
            "Number of Words: 16\n",
            "Average Word Length: 4.19\n",
            "\n",
            "Text: 'The product is okay. Nothing special but does the job.'\n",
            "Number of Sentences: 2\n",
            "Number of Words: 12\n",
            "Average Word Length: 3.75\n",
            "\n",
            "Text: 'I'm not sure if I like this. It's not what I expected but it's not terrible either.'\n",
            "Number of Sentences: 2\n",
            "Number of Words: 22\n",
            "Average Word Length: 3.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "## Question 3 (10 points):\n",
        "Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
        "\n",
        "Select the most important features you extracted above, rank the features based on their importance in the descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CRuXfV570ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9609d289-7edb-4220-d0e8-37c60c17fcf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Features Ranked by T-Test Scores:\n",
            "Feature: and, T-Score: inf\n",
            "Feature: but, T-Score: -inf\n",
            "Feature: worst, T-Score: 1.00\n",
            "Feature: works, T-Score: 1.00\n",
            "Feature: awful, T-Score: 1.00\n",
            "Feature: charm, T-Score: 1.00\n",
            "Feature: does, T-Score: -1.00\n",
            "Feature: either, T-Score: -1.00\n",
            "Feature: ever, T-Score: 1.00\n",
            "Feature: exceeded, T-Score: 1.00\n",
            "Feature: expectations, T-Score: 1.00\n",
            "Feature: expected, T-Score: -1.00\n",
            "Feature: experience, T-Score: 1.00\n",
            "Feature: had, T-Score: 1.00\n",
            "Feature: if, T-Score: -1.00\n",
            "Feature: job, T-Score: -1.00\n",
            "Feature: service, T-Score: 1.00\n",
            "Feature: product, T-Score: 1.00\n",
            "Feature: what, T-Score: -1.00\n",
            "Feature: ve, T-Score: 1.00\n",
            "Feature: this, T-Score: 1.00\n",
            "Feature: sure, T-Score: -1.00\n",
            "Feature: special, T-Score: -1.00\n",
            "Feature: love, T-Score: 1.00\n",
            "Feature: absolutely, T-Score: 1.00\n",
            "Feature: okay, T-Score: -1.00\n",
            "Feature: nothing, T-Score: -1.00\n",
            "Feature: not, T-Score: -1.00\n",
            "Feature: my, T-Score: 1.00\n",
            "Feature: the, T-Score: -0.45\n",
            "Feature: it, T-Score: -0.45\n",
            "Feature: terrible, T-Score: 0.00\n",
            "Feature: is, T-Score: 0.00\n",
            "Feature: like, T-Score: 0.00\n"
          ]
        }
      ],
      "source": [
        "#I am using t-test based method\n",
        "# You code here (Please add comments in the code):\n",
        "#importing required libraries\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Sample iput text\n",
        "texts = [\n",
        "    \"I absolutely love this product! It works like a charm and exceeded my expectations.\",  # positive\n",
        "    \"This is the worst experience I've ever had. Terrible service and awful product.\",       # negative\n",
        "    \"The product is okay. Nothing special but does the job.\",                               # neutral\n",
        "    \"I'm not sure if I like this. It's not what I expected but it's not terrible either.\"    # neutral\n",
        "]\n",
        "\n",
        "# Target labels: 1 = positive, 0 = negative, 2 = neutral\n",
        "labels = [1, 0, 2, 2]\n",
        "\n",
        "# Extracting Bag of Words features\n",
        "vectorizer = CountVectorizer()\n",
        "bow_matrix = vectorizer.fit_transform(texts)\n",
        "\n",
        "feature_names = np.array(vectorizer.get_feature_names_out())\n",
        "\n",
        "labels = np.array(labels)\n",
        "\n",
        "# sepearting the text into two groups\n",
        "group1 = bow_matrix[labels != 2].toarray()\n",
        "group2 = bow_matrix[labels == 2].toarray()\n",
        "\n",
        "# performing the t-test\n",
        "t_scores, p_values = ttest_ind(group1, group2, axis=0)\n",
        "\n",
        "# Ranking features in descending order\n",
        "sorted_indices = np.argsort(np.abs(t_scores))[::-1]\n",
        "top_features = feature_names[sorted_indices]\n",
        "top_t_scores = t_scores[sorted_indices]\n",
        "\n",
        "# Displayng the most important features with their t-test scores\n",
        "print(\"Top Features Ranked by T-Test Scores:\")\n",
        "for i in range(len(top_features)):\n",
        "    print(f\"Feature: {top_features[i]}, T-Score: {top_t_scores[i]:.2f}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "## Question 4 (10 points):\n",
        "Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4HoWK-i70ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff8641ea-b107-42f1-e1a7-13c35a2230e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranked Documents based on Cosine Similarity with Query:\n",
            "Rank 1:\n",
            "Text: 'I absolutely love this product! It works like a charm and exceeded my expectations.'\n",
            "Cosine Similarity: 0.9783\n",
            "--------------------------------------------------------------------------------\n",
            "Rank 2:\n",
            "Text: 'I'm not sure if I like this. It's not what I expected but it's not terrible either.'\n",
            "Cosine Similarity: 0.9000\n",
            "--------------------------------------------------------------------------------\n",
            "Rank 3:\n",
            "Text: 'This is the worst experience I've ever had. Terrible service and awful product.'\n",
            "Cosine Similarity: 0.8702\n",
            "--------------------------------------------------------------------------------\n",
            "Rank 4:\n",
            "Text: 'The product is okay. Nothing special but does the job.'\n",
            "Cosine Similarity: 0.8397\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Sample input text\n",
        "texts = [\n",
        "    \"I absolutely love this product! It works like a charm and exceeded my expectations.\",\n",
        "    \"This is the worst experience I've ever had. Terrible service and awful product.\",\n",
        "    \"The product is okay. Nothing special but does the job.\",\n",
        "    \"I'm not sure if I like this. It's not what I expected but it's not terrible either.\"\n",
        "]\n",
        "\n",
        "# query that matches relevant documents\n",
        "query = \"I really like this product and it exceeded my expectations.\"\n",
        "\n",
        "# Function for computing BERT embeddings\n",
        "def get_bert_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        # Use the [CLS] token's representation as the sentence embedding\n",
        "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "    return cls_embedding\n",
        "\n",
        "# Compute embeddings for all texts and the query\n",
        "query_embedding = get_bert_embedding(query)\n",
        "\n",
        "text_embeddings = []\n",
        "for text in texts:\n",
        "    embedding = get_bert_embedding(text)\n",
        "    text_embeddings.append(embedding)\n",
        "\n",
        "query_embedding_np = query_embedding.cpu().numpy()\n",
        "text_embeddings_np = [embedding.cpu().numpy() for embedding in text_embeddings]\n",
        "\n",
        "# Calculate cosine similarity between the query and each document\n",
        "cosine_similarities = [cosine_similarity(query_embedding_np, text_embedding)[0][0] for text_embedding in text_embeddings_np]\n",
        "\n",
        "# Rank the documents by similarity score (descending order)\n",
        "ranked_indices = np.argsort(cosine_similarities)[::-1]\n",
        "ranked_texts = [texts[i] for i in ranked_indices]\n",
        "ranked_similarities = [cosine_similarities[i] for i in ranked_indices]\n",
        "\n",
        "# Displaying the ranked documents with their similarity scores in descending order\n",
        "print(\"Ranked Documents based on Cosine Similarity with Query:\")\n",
        "for i, (text, similarity) in enumerate(zip(ranked_texts, ranked_similarities)):\n",
        "    print(f\"Rank {i+1}:\")\n",
        "    print(f\"Text: '{text}'\")\n",
        "    print(f\"Cosine Similarity: {similarity:.4f}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on extracting features from text data. What were the key concepts or techniques you found most beneficial in understanding the process?\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in completing this exercise?\n",
        "\n",
        "Relevance to Your Field of Study: How does this exercise relate to the field of NLP?\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "I found the first question as a good challenge to me, where I took \"Sentiment Analysis\" as a text classifiction task.\n",
        "I have also disscussed some features such as Bag of Words (BoW), N-grams, POS tagging, sentiment lexicon scores, and text readability.\n",
        "I also explored feature extraction techniques such as Bag of Words, TF-IDF, and word embeddings, including using BERT.\n",
        "Understanding how these methods convert raw text into numerical representations was crucial.\n",
        "Learning to calculate cosine similarity using BERT embeddings provided practical insight into comparing the semantic similarity of texts.\n",
        "Working on extracting features from text data was an enriching experience that enhanced my understanding of Natural Language Processing (NLP).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "CAq0DZWAhU9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}